{
 "projects":[
    { "name": "Global Disasters 1989-2018",
        "subtitle":"Visualizing the density and impact of natural disasters and conflicts around the world over time.",
        "type":["Full-Stack", "Data Visualization"],
        "tags": ["React","Typescript","WebGL","D3","Pandas","Python","Scikit-learn"],
        "description": "Mobi has begun to collaborate with non-profit organizations for disaster response to help with the planning. This visualization was one of our first attempts to overlay the global disasters and conflicts and get a first view of their impact our the world. Using a hexagonal grid, the map visualizes the disasters and conflicts aggregated by hexagon cell and by date.",
        "video":"../assets/video/disasters.mp4",
        "img":"../assets/img/disasters.jpg",
        "bwImg":"../assets/img/disasters_bw.jpg",
        "year":"2023"
      },
    { "name": "Climate Data in Travel Exploration",
        "subtitle":"A storytelling example of how Mobi in incorporating temporal climate parameters in offering travel plans.",
        "type":[ "Data Visualization"],
        "tags": ["Javascript","Mapbox","D3"],
        "description": "An interactive visualization that tells the story of how we use climate data layers to showcase the exploratory process of selecting a destination to visit and explore coral reefs. ",
        "video":"../assets/video/coral_reef.mp4",
        "img":"../assets/img/coral_reef.jpg",
        "bwImg":"../assets/img/coral_reef_bw.jpg",
        "year":"2023"
      },
      { "name": "Global Region Ranking by User Preferences",
        "subtitle":"An internal data visualization tool for data exploration",
        "type":["Full-Stack", "Data Visualization"],
        "tags": ["React","WebGL", "deck.gl","D3","Python","Scikit-learn"],
        "description": "This is a first prototype of an internal data visualization tool for Mobi's research scientists. The interface allows the user to filter the dataset by selecting tags of their preferences and retrieve the highest scored h3 cells globally.",
        "video":"../assets/video/h3.mp4",
        "img":"../assets/img/h3.jpg",
        "bwImg":"../assets/img/h3_bw.jpg",
        "year":"2023"
      },
    { "name": "Point-cloud Soundscape Clusters",
      "subtitle":"A data visualization tool for data exploration",
      "type":["Full-Stack", "Data Visualization"],
      "tags": ["Javascript","WebGL","D3","Pandas","Python","Scikit-learn"],
      "description": "Research project (thesis) supervised by Arvind Satyanarayan & Terry Knight. Studied the impact of COVID-19 on urban environments through sound. Analyzed audio & geospatial data to extract geo-sound clusters using Python, Machine Learning (Scikit-learn), UMAP & Matplotlib. Developed a notational language to visualize urban sound clusters & prototyped an interactive web interface using Javascript, D3 & WebGL.",
      "video":"../assets/video/umap_2.m4v",
      "img":"../assets/img/Umap_final.jpg",
      "bwImg":"../assets/img/Umap_final_bw.jpg",
      "year":"2022"
    },
    { "name": "Visualize changes in 3D Cartography",
      "subtitle":"Comparing geospatial transformations with 3D point clouds",
      "type":[ "Data Visualization"],
      "tags": ["Javascript","Three.js","WebGL"],
      "description": "A 3D point cloud web data visualization that compares photogrammetry models of 3D scanned spaces and identifies changes in the space by performing comparison between two dense 3D points clouds. In collaboration with the MIT Virtual Experience Lab.",
      "video":"../assets/video/3dCarto.m4v",
      "img":"../assets/img/3dCarto.jpg",
      "bwImg":"../assets/img/3dCarto_bw.jpg",
      "year":"2020"
    },
    { "name": "Visualizing Multimodal Learning",
      "subtitle":"Explaining Deep Learning with Data Visualization",
      "type":["Data Visualization","Machine Learning"],
      "tags": ["Javascript","Python", "Tensorflow"],
      "description": "This project was developed as part of my final project for the Fall 2021 Deep Learning class that I took at MIT. I developed an interactive data visualization for A.Owens and A.Efros(2018) paper on audio-visual scene analysis. I experimented and tested their model on different inputs from the Google AudioSet and produced a blog to bring new insight and help explain the proposed machine learning model.",
      "video":"../assets/video/multimodal_learning.m4v",
      "img":"../assets/img/ml2.jpg",
      "bwImg":"../assets/img/ml2_bw.jpg",
      "year":"2021"
    },
    { "name": "Mapping the walking route",
      "subtitle":"Using machine learning to visualize sound events along a route",
      "type":["Full-Stack", "Data Analysis","Data Visualization", "Machine Learning"],
      "tags": ["Javascript","Python", "Mapbox"],
      "description": "This research combines geolocation data from GPS and audio data to study how different sounds affect the walking experience. The visualization combines two different representations methods to show the correlation between the sound events and the walking pace. Yamnet, a ML model was used to perform sound classification on the audio data. This project was developed as part of the Interactive Data Visualization class in the Spring of 2021, and it served as an initial prototype for my thesis.",
      "video":"../assets/video/mapping.m4v",
      "img":"../assets/img/mapbox.jpg",
      "bwImg":"../assets/img/mapbox_bw.jpg",
      "year":"2020"
    },
    { "name": "Atlas of Telecommunication Technology",
      "subtitle":"Visualizing trends in communication technology in the 20th century",
      "type":["Data Visualization"],
      "tags": ["Javascript","D3","Python"],
      "description": "An interactive data visualization that shows how trends manifest throughout communications technology in the 20th century. Innovations such as the telephone, TV, and internet permanently change global communication, and adoption of novel technology is very disproportionate between countries. Throughout the history of technology adoption documented in this dataset, a country's GDP is strongly correlated with how quickly it is able to adopt its use of a technology per capita. This project was developed as part of the Interactive Data Visualization class at MIT.",
      "video":"../assets/video/atlas.m4v",
      "img":"../assets/img/atlas.jpg",
      "bwImg":"../assets/img/atlas_bw.jpg",
      "year":"2020"
    },
    { "name": "Soundscapes as Urban Transformation",
      "subtitle":"Introducing a notational language that represents the shifting relationships between sound, space, and movement",
      "type":["Full-Stack", "Data Visualization", "Machine Learning", "Data Analysis"],
      "tags": ["Javascript","Python", "Scikit-learn","p5"],
      "description": "Research project (thesis) supervised by Arvind Satyanarayan & Terry Knight. Studied the impact of COVID-19 on urban environments through sound. Analyzed audio & geospatial data to extract geo-sound clusters using Python, Machine Learning (Scikit-learn), UMAP & Matplotlib. Developed a notational language to visualize urban sound clusters & prototyped an interactive web interface using Javascript, D3 & WebGL",
      "video":"../assets/video/phases_comp.m4v",
      "img":"../assets/img/phases_comp.jpg",
      "bwImg":"../assets/img/phases_comp_bw.jpg",
      "year":"2022"
    }
 ]
}